import numpy as np
import pytest
from lbforaging.foraging.aecEnvironment import ForagingEnv, Action
from pettingzoo.test import api_test


def manhattan_distance(x, y):
    return sum(abs(a - b) for a, b in zip(x, y))


@pytest.fixture
def simple2p1f():
    """Create a simple 2 player, 1 food environment with controlled setup."""
    env = ForagingEnv(
        players=2,
        min_player_level=2,
        max_player_level=2,
        min_food_level=2,
        max_food_level=2,
        field_size=(8, 8),
        max_num_food=1,
        sight=8,
        max_episode_steps=50,
        force_coop=False,
        normalize_reward=True,
        grid_observation=False,
        penalty=0.0
    )
    env.reset()
    
    # Set up controlled scenario
    env.field[:] = 0
    env.field[4, 4] = 2
    env._food_spawned = env.field.sum()
    
    env.players[0].position = (4, 3)
    env.players[1].position = (4, 5)
    env.players[0].level = 2
    env.players[1].level = 2
    
    env._gen_valid_moves()
    
    return env


@pytest.fixture
def simple2p1f_sight1():
    """Create a simple 2 player, 1 food environment with sight=1."""
    env = ForagingEnv(
        players=2,
        min_player_level=2,
        max_player_level=2,
        min_food_level=2,
        max_food_level=2,
        field_size=(8, 8),
        max_num_food=1,
        sight=1,
        max_episode_steps=50,
        force_coop=False,
        normalize_reward=True,
        grid_observation=False,
        penalty=0.0
    )
    env.reset()
    
    env.field[:] = 0
    env.field[4, 4] = 2
    env._food_spawned = env.field.sum()
    
    env.players[0].position = (4, 3)
    env.players[1].position = (4, 5)
    env.players[0].level = 2
    env.players[1].level = 2
    
    env._gen_valid_moves()
    
    return env


@pytest.fixture
def simple2p1f_sight2():
    """Create a simple 2 player, 1 food environment with sight=2."""
    env = ForagingEnv(
        players=2,
        min_player_level=2,
        max_player_level=2,
        min_food_level=2,
        max_food_level=2,
        field_size=(8, 8),
        max_num_food=1,
        sight=2,
        max_episode_steps=50,
        force_coop=False,
        normalize_reward=True,
        grid_observation=False,
        penalty=0.0
    )
    env.reset()
    
    env.field[:] = 0
    env.field[4, 4] = 2
    env._food_spawned = env.field.sum()
    
    env.players[0].position = (4, 3)
    env.players[1].position = (4, 5)
    env.players[0].level = 2
    env.players[1].level = 2
    
    env._gen_valid_moves()
    
    return env


def test_aec_api():
    """Test PettingZoo AEC API compliance."""
    env = ForagingEnv(
        players=2,
        min_player_level=1,
        max_player_level=2,
        min_food_level=1,
        max_food_level=None,
        field_size=(8, 8),
        max_num_food=2,
        sight=8,
        max_episode_steps=50,
        force_coop=False,
        normalize_reward=True,
        grid_observation=False,
        penalty=0.0
    )
    
    # api_test checks for compliance with PettingZoo AEC API
    api_test(env, num_cycles=100, verbose_progress=False)


def test_aec_manual_cycle():
    """Test basic manual stepping through the environment."""
    env = ForagingEnv(
        players=2,
        min_player_level=1,
        max_player_level=2,
        min_food_level=1,
        max_food_level=None,
        field_size=(8, 8),
        max_num_food=2,
        sight=8,
        max_episode_steps=50,
        force_coop=False
    )
    env.reset()
    
    step_count = 0
    for agent in env.agent_iter(max_iter=100):
        observation, reward, termination, truncation, info = env.last()
        if termination or truncation:
            action = None
        else:
            action = env.action_space(agent).sample()
        
        env.step(action)
        step_count += 1
    
    assert step_count > 0
    env.close()


def test_food_spawning_spacing():
    """Test that food spawns with proper spacing constraints."""
    env = ForagingEnv(
        players=2,
        min_player_level=1,
        max_player_level=2,
        min_food_level=1,
        max_food_level=2,
        field_size=(6, 6),
        max_num_food=2,
        sight=6,
        max_episode_steps=50,
        force_coop=False
    )
    
    for _ in range(100):
        env.reset()
        
        foods = [np.array(f) for f in zip(*env.field.nonzero())]
        # Should have 2 foods
        assert len(foods) == 2
        
        # Foods must not be within 2 steps of each other
        assert manhattan_distance(foods[0], foods[1]) > 2
        
        # Food cannot be placed in first or last col/row
        for food in foods:
            assert food[0] not in [0, 5]
            assert food[1] not in [0, 5]


def test_food_spawning_multiple():
    """Test food spawning with 3 foods."""
    env = ForagingEnv(
        players=2,
        min_player_level=1,
        max_player_level=2,
        min_food_level=1,
        max_food_level=2,
        field_size=(8, 8),
        max_num_food=3,
        sight=8,
        max_episode_steps=50,
        force_coop=False
    )
    
    for _ in range(100):
        env.reset()
        
        foods = [np.array(f) for f in zip(*env.field.nonzero())]
        # Should have 3 foods
        assert len(foods) == 3
        
        # All foods must be properly spaced
        assert manhattan_distance(foods[0], foods[1]) > 2
        assert manhattan_distance(foods[0], foods[2]) > 2
        assert manhattan_distance(foods[1], foods[2]) > 2


def test_reward_cooperative_loading(simple2p1f):
    """Test reward when both players cooperatively load food."""
    env = simple2p1f
    
    # Both players load (Action.LOAD = 5)
    actions = [Action.LOAD.value, Action.LOAD.value]
    
    # Execute actions for both agents
    env.reset()
    env.field[:] = 0
    env.field[4, 4] = 2
    env._food_spawned = env.field.sum()
    env.players[0].position = (4, 3)
    env.players[1].position = (4, 5)
    env._gen_valid_moves()
    
    rewards_collected = []
    for i, agent in enumerate(env.agent_iter(max_iter=2)):
        obs, reward, term, trunc, info = env.last()
        env.step(actions[i])
        if i == 1:  # After both actions processed
            rewards_collected = [env.players[0].reward, env.players[1].reward]
    
    # Both should get equal reward (normalized: 0.5 each)
    assert abs(rewards_collected[0] - 0.5) < 0.01
    assert abs(rewards_collected[1] - 0.5) < 0.01


def test_reward_single_player_loading(simple2p1f):
    """Test reward when only one player loads."""
    env = simple2p1f
    
    # Only player 1 loads, player 0 does nothing
    actions = [Action.NONE.value, Action.LOAD.value]
    
    env.reset()
    env.field[:] = 0
    env.field[4, 4] = 2
    env._food_spawned = env.field.sum()
    env.players[0].position = (4, 3)
    env.players[1].position = (4, 5)
    env._gen_valid_moves()
    
    rewards_collected = []
    for i, agent in enumerate(env.agent_iter(max_iter=2)):
        obs, reward, term, trunc, info = env.last()
        env.step(actions[i])
        if i == 1:
            rewards_collected = [env.players[0].reward, env.players[1].reward]
    
    # Player 1 should get full reward, player 0 gets nothing
    assert rewards_collected[0] == 0
    assert abs(rewards_collected[1] - 1.0) < 0.01


def test_seeding_reproducibility():
    """Test that seeding produces reproducible results."""
    episodes_per_seed = 5
    
    for seed in range(3):
        env1 = ForagingEnv(
            players=2,
            min_player_level=1,
            max_player_level=2,
            min_food_level=1,
            max_food_level=2,
            field_size=(8, 8),
            max_num_food=2,
            sight=8,
            max_episode_steps=50,
            force_coop=False
        )
        
        env2 = ForagingEnv(
            players=2,
            min_player_level=1,
            max_player_level=2,
            min_food_level=1,
            max_food_level=2,
            field_size=(8, 8),
            max_num_food=2,
            sight=8,
            max_episode_steps=50,
            force_coop=False
        )
        
        fields1 = []
        positions1 = []
        levels1 = []
        
        env1.seed(seed)
        for _ in range(episodes_per_seed):
            env1.reset()
            fields1.append(env1.field.copy())
            positions1.append([p.position for p in env1.players])
            levels1.append([p.level for p in env1.players])
        
        fields2 = []
        positions2 = []
        levels2 = []
        
        env2.seed(seed)
        for _ in range(episodes_per_seed):
            env2.reset()
            fields2.append(env2.field.copy())
            positions2.append([p.position for p in env2.players])
            levels2.append([p.level for p in env2.players])
        
        # Verify reproducibility
        for i in range(episodes_per_seed):
            assert np.array_equal(fields1[i], fields2[i]), \
                f"Fields not identical for episode {i} with seed {seed}"
            assert positions1[i] == positions2[i], \
                f"Positions not identical for episode {i} with seed {seed}"
            assert levels1[i] == levels2[i], \
                f"Levels not identical for episode {i} with seed {seed}"


def test_partial_observability_sight1(simple2p1f_sight1):
    """Test partial observability with sight=1."""
    env = simple2p1f_sight1
    obs = env._make_gym_obs()
    
    # With sight=1 and players at (4,3) and (4,5), they can't see each other
    # Check that the other player is not visible (position should be -1)
    assert obs[0][-2] == -1  # Player 0 can't see player 1
    assert obs[1][-2] == -1  # Player 1 can't see player 0


def test_partial_observability_sight2(simple2p1f_sight2):
    """Test partial observability with sight=2."""
    env = simple2p1f_sight2
    obs = env._make_gym_obs()
    
    # With sight=2 and players at (4,3) and (4,5), they CAN see each other
    assert obs[0][-2] > -1  # Player 0 can see player 1
    assert obs[1][-2] > -1  # Player 1 can see player 0
    
    # Move player 0 away
    env.players[0].position = (1, 1)
    env._gen_valid_moves()
    obs = env._make_gym_obs()
    
    # Now they can't see each other
    assert obs[0][-2] == -1
    assert obs[1][-2] == -1


def test_full_observability(simple2p1f):
    """Test full observability (sight=8 on 8x8 field)."""
    env = simple2p1f
    obs = env._make_gym_obs()
    
    # With full sight, players can always see each other
    assert obs[0][-2] > -1
    assert obs[1][-2] > -1
    
    # Even after moving
    env.players[0].position = (1, 1)
    env._gen_valid_moves()
    obs = env._make_gym_obs()
    
    assert obs[0][-2] > -1
    assert obs[1][-2] > -1


def test_episode_termination():
    """Test that episodes terminate correctly."""
    env = ForagingEnv(
        players=2,
        min_player_level=2,
        max_player_level=2,
        min_food_level=1,
        max_food_level=1,
        field_size=(8, 8),
        max_num_food=1,
        sight=8,
        max_episode_steps=10,  # Short episode
        force_coop=False
    )
    
    env.reset()
    
    terminated = False
    truncated = False
    step_count = 0
    
    for agent in env.agent_iter(max_iter=50):
        obs, reward, termination, truncation, info = env.last()
        
        if termination or truncation:
            terminated = termination
            truncated = truncation
            env.step(None)
        else:
            env.step(env.action_space(agent).sample())
            step_count += 1
    
    # Should terminate or truncate within max steps
    assert terminated or truncated or step_count >= 10


def test_collision_detection():
    """Test that player collisions are handled correctly."""
    env = ForagingEnv(
        players=2,
        min_player_level=1,
        max_player_level=1,
        min_food_level=1,
        max_food_level=1,
        field_size=(8, 8),
        max_num_food=1,
        sight=8,
        max_episode_steps=50,
        force_coop=False
    )
    
    env.reset()
    
    # Place players next to each other
    env.players[0].position = (4, 4)
    env.players[1].position = (4, 5)
    env.field[:] = 0  # Clear field
    env._gen_valid_moves()
    
    initial_pos_0 = env.players[0].position
    initial_pos_1 = env.players[1].position
    
    # Both try to move to the same location
    actions = [Action.EAST.value, Action.WEST.value]  # Both move towards (4,5)/(4,4)
    
    for i, agent in enumerate(env.agent_iter(max_iter=2)):
        env.step(actions[i])
    
    # Positions should not have changed due to collision
    # (or at least they shouldn't occupy the same cell)
    assert env.players[0].position != env.players[1].position


def test_collision_same_cell(simple2p1f):
    """Test two agents trying to move to the exact same cell at the same time."""
    env = simple2p1f
    env.reset()
    
    # Place P0 at (2,1) and P1 at (2,3)
    env.players[0].position = (2, 1)
    env.players[1].position = (2, 3)
    env.field[:] = 0
    env._gen_valid_moves()
    
    # Both move towards (2,2)
    # AEC requires stepping through agents.
    env.step(Action.EAST.value) # Agent 0 moves EAST to (2,2)
    env.step(Action.WEST.value) # Agent 1 moves WEST to (2,2)
    
    # After cycle, positions should remain unchanged because of collision
    assert env.players[0].position == (2, 1)
    assert env.players[1].position == (2, 3)


def test_swap_positions(simple2p1f):
    """Test two agents swapping positions (should be allowed in this implementation)."""
    env = simple2p1f
    env.reset()
    
    # Place P0 at (2,2) and P1 at (2,3)
    env.players[0].position = (2, 2)
    env.players[1].position = (2, 3)
    env.field[:] = 0
    env._gen_valid_moves()
    
    # P0 moves EAST (to 2,3), P1 moves WEST (to 2,2)
    env.step(Action.EAST.value) # Agent 0
    env.step(Action.WEST.value) # Agent 1
    
    # Positions should swap because they don't 'collide' in AEC as their moves are processed?
    # Wait, my refactor processes ALL buffered actions at once.
    # If they are processed at once, and target pos is the other's current pos...
    # My logic:
    #   collisions = defaultdict(list)
    #   for player, action in zip(players, actions):
    #       target_pos = ...
    #       collisions[target_pos].append(player)
    #   for k, v in collisions.items():
    #       if len(v) > 1: continue
    #       v[0].position = k
    
    # So if P0 targets (2,3) and P1 targets (2,2):
    # collisions[(2,3)] = [P0] -> valid!
    # collisions[(2,2)] = [P1] -> valid!
    # They swap!
    
    assert env.players[0].position == (2, 3)
    assert env.players[1].position == (2, 2)


def test_loading_logic_normalization(simple2p1f):
    """Test verify the reward normalization logic."""
    env = simple2p1f
    env.reset()
    
    # Place food at (2,2) with level 2
    env.field[:] = 0
    env.field[2, 2] = 2
    env._food_spawned = 2.0 # Total food spawned value
    
    # Place P0 at (2,1) and P1 at (2,3). Both level 1.
    env.players[0].position = (2, 1)
    env.players[0].level = 1
    env.players[1].position = (2, 3)
    env.players[1].level = 1
    env._gen_valid_moves()
    
    # Both LOAD
    # Because AEC needs to cycle through agents, we step through them
    for _ in env.agent_iter(max_iter=2):
        obs, reward, term, trunc, info = env.last()
        env.step(Action.LOAD.value)
    
    # Total Level = 1 + 1 = 2. Food = 2.
    # Reward unnormalized = PlayerLevel * Food = 1 * 2 = 2.
    # Normalization factor = TotalLevel (2) * TotalFoodSpawned (2.0) = 4.0.
    # Expected normalized reward = 2 / 4 = 0.5.
    
    # Rewards are collected in env.players[i].reward during step()
    # BUT in AEC, rewards are distributed.
    # The `last()` call returns reward for the *current* agent selection.
    # My test `test_reward_cooperative_loading` checked `env.players[i].reward`.
    
    assert env.players[0].reward == 0.5
    assert env.players[1].reward == 0.5
    assert env.field[2, 2] == 0 # Food removed


if __name__ == "__main__":
    pytest.main([__file__, "-v"])
